{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MerveNazlim/CatNN/blob/main/SvsBsstt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lfWEOVqLGxGG"
   },
   "outputs": [],
   "source": [
    "import random as p\n",
    "\n",
    "p.seed(10)\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "#from preprocess import mkdir_p, unique_filename\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "\n",
    "# h5py\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(400)\n",
    "from tensorflow import keras\n",
    "# keras\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras import models as Km\n",
    "from tensorflow.keras import layers as Kl\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler,minmax_scale\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from functools import partial\n",
    "from tensorflow.keras import initializers\n",
    "import numpy as np\n",
    "seed = 400\n",
    "np.random.seed(seed)\n",
    "import mplhep as hep\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Sso62vCKCR9c"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iKjYoU9RutdF"
   },
   "outputs": [],
   "source": [
    " def mkdir_p(path) :\n",
    "\n",
    "    import errno\n",
    "\n",
    "    \"\"\"\n",
    "    Make a directory, if it exists silence the exception\n",
    "\n",
    "    Args:\n",
    "        path : full directory path to be made\n",
    "    \"\"\"\n",
    "\n",
    "    try :\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc :\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path) :\n",
    "            pass\n",
    "        else :\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wNNxw-w7QUM7"
   },
   "outputs": [],
   "source": [
    "path_tosave = '/mnt/c/Users/aaron/Desktop/'\n",
    "file_name = 'sstt'\n",
    "path_tosave = path_tosave + file_name\n",
    "mkdir_p(path_tosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eeOlYDqIJN5R"
   },
   "outputs": [],
   "source": [
    "class Sample :\n",
    "\n",
    "    \"\"\"\n",
    "    Sample\n",
    "\n",
    "    This class will hold the feature data for a given sample.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name = \"\", class_label = -1, input_data = None) :\n",
    "        \"\"\"\n",
    "        Sample constructor\n",
    "\n",
    "        Args :\n",
    "            name : descriptive name of the sample (obtained from the input\n",
    "                pre-processed file)\n",
    "            input_data : numpy array of the data from the pre-processed file\n",
    "                (expects an array of dtype = np.float64, not a structured array!)\n",
    "            class_label : input class label as found in the input pre-processed\n",
    "                file\n",
    "        \"\"\"\n",
    "\n",
    "        if input_data.dtype != np.float64 :\n",
    "            raise Exception(\"ERROR Sample input data must be type 'np.float64', input is '{}'\".format(input_data.dtype))\n",
    "\n",
    "        if class_label < 0 :\n",
    "            raise ValueError(\"ERROR Sample (={})class label is not set (<0)\".format(name, class_label))\n",
    "\n",
    "        print(\"Creating sample {} (label = {})\".format(name, class_label))\n",
    "\n",
    "        self._name = name\n",
    "        self._class_label = class_label\n",
    "        self._input_data = input_data\n",
    "        self._regression_inputs = None\n",
    "\n",
    "    def name(self) :\n",
    "        return self._name\n",
    "    def class_label(self) :\n",
    "        return self._class_label\n",
    "    def data(self) :\n",
    "        return self._input_data\n",
    "    @property\n",
    "    def regression_inputs(self) :\n",
    "        return self._regression_inputs\n",
    "    @regression_inputs.setter\n",
    "    def regression_inputs(self, data) :\n",
    "        self._regression_inputs = data\n",
    "        \n",
    "\n",
    "\n",
    "class DataScaler :\n",
    "\n",
    "    \"\"\"\n",
    "    DataScaler\n",
    "\n",
    "    This class will hold the scaling information needed for the training\n",
    "    features (variables) contained in the input, pre-processed file.\n",
    "    Its constructor takes as input the scaling data dataset object\n",
    "    contained in the pre-processed file and it builds the associated\n",
    "    feature-list and an associated dictionary to store the scaling\n",
    "    parameters for each of the input features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scaling_dataset = None, ignore_features = []) :\n",
    "\n",
    "        \"\"\"\n",
    "        ScalingData constructor\n",
    "\n",
    "        Args:\n",
    "            scaling_dataset : input HDF5 dataset object which contains the\n",
    "                scaling data and feature-list\n",
    "        \"\"\"\n",
    "\n",
    "        self._raw_feature_list = []\n",
    "        self._feature_list = []\n",
    "        self._scaling_dict = {}\n",
    "        self._mean = []\n",
    "        self._scale = []\n",
    "        self._var = []\n",
    "        self.load(scaling_dataset, ignore_features)\n",
    "\n",
    "    def load(self, scaling_dataset = None, ignore_features = []) :\n",
    "\n",
    "        self._raw_feature_list = list( scaling_dataset['name'] )\n",
    "        self._feature_list = list( filter( lambda x : x not in ignore_features, self._raw_feature_list ) )\n",
    "\n",
    "        #self._mean = scaling_dataset['mean']\n",
    "        #self._scale = scaling_dataset['scale']\n",
    "        #self._var = scaling_dataset['var']\n",
    "\n",
    "\n",
    "        for x in scaling_dataset :\n",
    "            name, mean, scale, var = x['name'], x['mean'], x['scale'], x['var']\n",
    "            if name in ignore_features : continue\n",
    "            self._scaling_dict[name] = { 'mean' : mean, 'scale' : scale, 'var' : var }\n",
    "            self._mean.append(mean)\n",
    "            self._scale.append(scale)\n",
    "            self._var.append(var)\n",
    "\n",
    "        self._mean = np.array(self._mean, dtype = np.float64)\n",
    "        self._scale = np.array(self._scale, dtype = np.float64)\n",
    "        self._var = np.array(self._var, dtype = np.float64)\n",
    "\n",
    "    def raw_feature_list(self) :\n",
    "        return self._raw_feature_list\n",
    "\n",
    "    def feature_list(self) :\n",
    "        return self._feature_list\n",
    "\n",
    "    def scaling_dict(self) :\n",
    "        return self._scaling_dict\n",
    "\n",
    "    def get_params(self, feature = \"\") :\n",
    "        if feature in self._scaling_dict :\n",
    "            return self._scaling_dict[feature]\n",
    "        raise KeyError(\"requested feature (={}) not found in set of scaling features\".format(feature))\n",
    "\n",
    "    def mean(self) :\n",
    "        return self._mean\n",
    "    def scale(self) :\n",
    "        return self._scale\n",
    "    def var(self) :\n",
    "        return self._var\n",
    "\n",
    "def floatify(input_array, feature_list) :\n",
    "    ftype = [(name, float) for name in feature_list]\n",
    "    return input_array.astype(ftype).view(float).reshape(input_array.shape + (-1,))\n",
    "\n",
    "def load_input_file(args) :\n",
    "\n",
    "    \"\"\"\n",
    "    Check that the provided input HDF5 file is of the expected form\n",
    "    as defined by the pre-processing. Exits if this is not the case.\n",
    "    Returns a list of the sample names found in the file.\n",
    "\n",
    "    Args :\n",
    "        args : user input to the executable\n",
    "    \"\"\"\n",
    "\n",
    "    # check that the file can be found\n",
    "    if not os.path.isfile(args) :\n",
    "        print(\"ERROR provided input file (={}) is not found or is not a regular file\".format(args))\n",
    "        sys.exit()\n",
    "\n",
    "    samples_group_name = \"samples\"\n",
    "    scaling_group_name = \"scaling\"\n",
    "    scaling_data_name = \"scaling_data\"\n",
    "\n",
    "    found_samples = False\n",
    "    found_scalings = False\n",
    "    samples = []\n",
    "    data_scaler = None\n",
    "    #features_to_ignore = [\"Mll01\",\"Mll02\",\"Mll03\",\"Mll12\",\"Mll13\",\"Mll23\"]\n",
    "    features_to_ignore = [\"DeltaR_min_lep_bjet77\",\"DeltaR_max_lep_bjet77\"]\n",
    "    #features_to_ignore = [\"\"]\n",
    "\n",
    "    with h5py.File(args, 'r') as input_file :\n",
    "\n",
    "        # look up the scalings first, in order to build the feature list used for the Sample creation\n",
    "        if scaling_group_name in input_file :\n",
    "            found_scalings = True\n",
    "            scaling_group = input_file[scaling_group_name]\n",
    "            scaling_dataset = scaling_group[scaling_data_name]\n",
    "            data_scaler = DataScaler( scaling_dataset = scaling_dataset, ignore_features = features_to_ignore )\n",
    "            print(\"DataScaler found {} features to train on (there were {} total features in the input)\".format( len(data_scaler.feature_list()), len(data_scaler.raw_feature_list() )))\n",
    "        else :\n",
    "            print(\"scaling group (={}) not found in file\".format(scaling_group_name))\n",
    "            sys.exit()\n",
    "\n",
    "        # now build the samples\n",
    "        if samples_group_name in input_file :\n",
    "            found_samples = True\n",
    "            sample_group = input_file[samples_group_name]\n",
    "            for p in sample_group :\n",
    "                process_group = sample_group[p]\n",
    "                class_label = process_group.attrs['training_label']\n",
    "                s = Sample(name = p, class_label = int(class_label),\n",
    "                    input_data = floatify( process_group['train_features'][tuple(data_scaler.feature_list())], data_scaler.feature_list() ) )\n",
    "                #print(floatify( process_group['train_features'][tuple(data_scaler.feature_list())], data_scaler.feature_list() ))\n",
    "                samples.append(s)\n",
    "\n",
    "        else :\n",
    "            print(\"samples group (={}) not found in file\".format(samples_group_name))\n",
    "            sys.exit()\n",
    "\n",
    "    samples = sorted(samples, key = lambda x: x.class_label())\n",
    "\n",
    "    return samples, data_scaler\n",
    "\n",
    "def load_input_file_val(args) :\n",
    "\n",
    "    if not os.path.isfile(args) :\n",
    "        print(\"ERROR provided input file (={}) is not found or is not a regular file\".format(args))\n",
    "        sys.exit()\n",
    "\n",
    "    samples_group_name = \"samples\"\n",
    "    scaling_group_name = \"scaling\"\n",
    "    scaling_data_name = \"scaling_data\"\n",
    "\n",
    "    samples = []\n",
    "    data_scaler = None\n",
    "\n",
    "    with h5py.File(args, 'r', libver = 'latest') as input_file :\n",
    "\n",
    "        # look up the scaling first\n",
    "        if scaling_group_name in input_file :\n",
    "            scaling_group = input_file[scaling_group_name]\n",
    "            scaling_dataset = scaling_group[scaling_data_name]\n",
    "            data_scaler = DataScaler( scaling_dataset = scaling_dataset, ignore_features = [\"DeltaR_min_lep_bjet77\",\"DeltaR_max_lep_bjet77\"] )\n",
    "            print(\"DataScaler found {} features to use as inputs (there were {} total features in the input)\".format( len(data_scaler.feature_list()), len(data_scaler.raw_feature_list())))\n",
    "        else :\n",
    "            print(\"scaling group (={}) not found in file\".format(scaling_group_name))\n",
    "            sys.exit()\n",
    "\n",
    "        # build the samples\n",
    "        if samples_group_name in input_file :\n",
    "            sample_group = input_file[samples_group_name]\n",
    "            for p in sample_group :\n",
    "                process_group = sample_group[p]\n",
    "                class_label = process_group.attrs['training_label']\n",
    "                s = Sample(name = p, class_label = int(class_label),\n",
    "                    input_data = floatify( process_group['validation_features'][tuple(data_scaler.feature_list())], data_scaler.feature_list()))\n",
    "                samples.append(s)\n",
    "        else :\n",
    "            print(\"samples group (={}) not found in file\".format(samples_group_name))\n",
    "            sys.exit()\n",
    "\n",
    "    return samples, data_scaler\n",
    "\n",
    "def build_combined_input(training_samples, data_scaler = None, scale = True) :\n",
    "\n",
    "    targets = []\n",
    "    # used extended slicing to partition arbitrary number of samples\n",
    "    sample0, sample1, *other = training_samples\n",
    "\n",
    "    targets.extend( np.ones( sample0.data().shape[0] ) * sample0.class_label() )\n",
    "    targets.extend( np.ones( sample1.data().shape[0] ) * sample1.class_label() )\n",
    "\n",
    "    inputs = np.concatenate( (sample0.data(), sample1.data()), axis = 0)\n",
    "    for sample in other :\n",
    "        inputs = np.concatenate( (inputs, sample.data()) , axis = 0 )\n",
    "        targets.extend( np.ones( sample.data().shape[0] ) * sample.class_label() )\n",
    "\n",
    "    # perform scaling\n",
    "    input_notscale = inputs\n",
    "    if scale :\n",
    "        inputs = (inputs - data_scaler.mean()) / data_scaler.scale()\n",
    "        #print(inputs)\n",
    "\n",
    "    targets = np.array(targets, dtype = int )\n",
    "\n",
    "\n",
    "    return inputs, targets, input_notscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j0Ntqz_s4mHl"
   },
   "outputs": [],
   "source": [
    "def make_nn_output_plots_oddeven( path_tosave, model = None, inputs = None, samples = None, targets = None, events=None) :\n",
    "\n",
    "    #inputs_tek = inputs[events % 2==1]\n",
    "    #inputs_cift = inputs[events % 2==0]\n",
    "    \n",
    "    ## Workaround if no eventnumbers are used:\n",
    "    # Shuffle + split into two equal size arrays\n",
    "    np.random.shuffle(inputs)\n",
    "    inputs_tek = inputs_test[0:int(inputs.shape[0]/2),:]\n",
    "    inputs_cift = inputs_test[int(inputs.shape[0]/2):int(inputs_test.shape[0]),:]\n",
    "    \n",
    "    nn_scores = np.ones([targets.size,2])\n",
    "    nn_scores_tek = model[0].predict(inputs_tek,verbose = True)\n",
    "    nn_scores_cift = model[1].predict(inputs_cift,verbose = True)\n",
    "    nn_scores[0:int(inputs.shape[0]/2),0] = nn_scores_tek.flatten()\n",
    "    nn_scores[0:int(inputs.shape[0]/2),1] = abs(nn_scores_tek - 1).flatten()\n",
    "    nn_scores[int(inputs.shape[0]/2):int(inputs.shape[0]),0] = nn_scores_cift.flatten()\n",
    "    nn_scores[int(inputs.shape[0]/2):int(inputs.shape[0]),1] = abs(nn_scores_cift - 1).flatten()\n",
    "    class_labels = set(targets)\n",
    "    targets_list = list(targets)\n",
    "    nn_scores_dict = {}\n",
    "\n",
    "    # index the sample names by their class label\n",
    "    names = {}\n",
    "    for sample in samples :\n",
    "        names[sample.class_label()] = sample.name()\n",
    "\n",
    "    # break up the predicted scores by the class label\n",
    "    for ilabel, label in enumerate(class_labels) :\n",
    "        # left-most appearance of the label\n",
    "        left = targets_list.index(label)\n",
    "        # right-most appearance of the label\n",
    "        right = len(targets_list) - 1 - targets_list[::-1].index(label)\n",
    "        nn_scores_dict[label] = nn_scores[left:right+1]\n",
    "\n",
    "    # start plotting\n",
    "    for label in class_labels :\n",
    "        #fig, ax = plt.subplots(1,1)\n",
    "        fig = plt.figure()\n",
    "        plt.grid(color='k', which='both', linestyle='--', lw=0.5, alpha=0.1, zorder = 0)\n",
    "        plt.xlabel( \"NN output for label {}\".format(names[label]), horizontalalignment='right', x=1)\n",
    "        #ax.set_xlim([1e-2,1.0])\n",
    "        plt.xlim([0,1])\n",
    "        #plt.yscale('log')\n",
    "        histargs = {\"bins\":20, \"range\":(0,1.), \"density\":True, \"histtype\":'step'}\n",
    "        #binning = np.arange(0,1,0.02)\n",
    "        #centers = (binning[1:-2] + binning[2:-1])/2\n",
    "        #ax.set_xlim((centers[0]-0.1, centers[-1]+0.1)) \n",
    "        for sample_label in nn_scores_dict :\n",
    "            sample_scores_for_label = nn_scores_dict[sample_label][:]\n",
    "            print(sample_scores_for_label)\n",
    "            #sample_weights = sample_with_label(sample_label, samples).eventweights\n",
    "\n",
    "            #yields, _ = np.histogram(sample_scores_for_label, bins = binning)\n",
    "            plt.hist(sample_scores_for_label,label = names[sample_label], **histargs)\n",
    "            #yields = yields/yields.sum()\n",
    "            #ax.step(centers, yields[1:-1], label = names[sample_label], where = 'mid')\n",
    "            \n",
    "            #ax.hist(sample_scores_for_label, bins = binning, alpha = 0.3, label = names[sample_label], density = True)\n",
    "        plt.legend(loc='best', frameon = False)\n",
    "        savename = \"nn_outputs_class_{}.pdf\".format( names[label])\n",
    "\n",
    "        savename = \"{}/{}\".format(path_tosave, savename) \n",
    "        plt.savefig(savename, bbox_inches = 'tight', dpi = 200)\n",
    "       # savename = \"nn_outputs_{}_class_{}.pdf\".format(path_tosave, names[label])\n",
    "\n",
    "     #   savename = \"{}/{}\".format(path_tosave, savename) \n",
    "     #   plt.savefig(savename, bbox_inches = 'tight', dpi = 200)\n",
    "\n",
    "    return nn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CfCXIMFm5rCV"
   },
   "outputs": [],
   "source": [
    "def make_nn_output_plots( model = None, inputs = None, samples = None, targets = None) :\n",
    "\n",
    "    # set of scores for each label: shape = (n_samples, n_outputs)\n",
    "    nn_scores = model.predict(inputs,verbose = True)\n",
    "\n",
    "    class_labels = set(targets)\n",
    "    targets_list = list(targets)\n",
    "    nn_scores_dict = {}\n",
    "\n",
    "    # index the sample names by their class label\n",
    "    names = {}\n",
    "    for sample in samples :\n",
    "        names[sample.class_label()] = sample.name()\n",
    "\n",
    "    # break up the predicted scores by the class label\n",
    "    for ilabel, label in enumerate(class_labels) :\n",
    "        # left-most appearance of the label\n",
    "        left = targets_list.index(label)\n",
    "        # right-most appearance of the label\n",
    "        right = len(targets_list) - 1 - targets_list[::-1].index(label)\n",
    "        nn_scores_dict[label] = nn_scores[left:right+1]\n",
    "\n",
    "    # start plotting\n",
    "    for label in class_labels :\n",
    "        #fig, ax = plt.subplots(1,1)\n",
    "        fig = plt.figure()\n",
    "        plt.grid(color='k', which='both', linestyle='--', lw=0.5, alpha=0.1, zorder = 0)\n",
    "        plt.xlabel( \"NN output for label {}\".format(names[label]), horizontalalignment='right', x=1)\n",
    "        #ax.set_xlim([1e-2,1.0])\n",
    "        plt.xlim([0,1])\n",
    "        #plt.yscale('log')\n",
    "        histargs = {\"bins\":20, \"range\":(0,1.), \"density\":True, \"histtype\":'step'}\n",
    "        #binning = np.arange(0,1,0.02)\n",
    "        #centers = (binning[1:-2] + binning[2:-1])/2\n",
    "        #ax.set_xlim((centers[0]-0.1, centers[-1]+0.1)) \n",
    "        for sample_label in nn_scores_dict :\n",
    "            sample_scores_for_label = nn_scores_dict[sample_label][:]\n",
    "            print(sample_scores_for_label)\n",
    "            #sample_weights = sample_with_label(sample_label, samples).eventweights\n",
    "\n",
    "            #yields, _ = np.histogram(sample_scores_for_label, bins = binning)\n",
    "            plt.hist(sample_scores_for_label,label = names[sample_label], **histargs)\n",
    "            #yields = yields/yields.sum()\n",
    "            #ax.step(centers, yields[1:-1], label = names[sample_label], where = 'mid')\n",
    "            \n",
    "            #ax.hist(sample_scores_for_label, bins = binning, alpha = 0.3, label = names[sample_label], density = True)\n",
    "        plt.legend(loc='best', frameon = False)\n",
    "        savename = \"nn_outputs_class_{}.pdf\".format( names[label])\n",
    "\n",
    "        savename = \"{}/{}\".format(path_tosave, savename) \n",
    "        plt.savefig(savename, bbox_inches = 'tight', dpi = 200)\n",
    "       # savename = \"nn_outputs_{}_class_{}.pdf\".format(path_tosave, names[label])\n",
    "\n",
    "     #   savename = \"{}/{}\".format(path_tosave, savename) \n",
    "     #   plt.savefig(savename, bbox_inches = 'tight', dpi = 200)\n",
    "\n",
    "    return nn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z7EMoV0kqBrt"
   },
   "outputs": [],
   "source": [
    "def ScaleWeights(y,w):\n",
    "    sum_wpos = sum( w[i] for i in range(len(y)) if y[i] == 1.0  )\n",
    "    sum_wneg = sum( w[i] for i in range(len(y)) if y[i] == 0.0  )\n",
    "\n",
    "    for i in range(len(w)):\n",
    "        if (y[i]==1.0):\n",
    "            w[i] = w[i] * (0.5/sum_wpos)\n",
    "        else:\n",
    "            w[i] = w[i] * (0.5/sum_wneg)\n",
    "\n",
    "    w_av = sum(w)/len(w)\n",
    "    w[:] = [x/w_av for x in w]\n",
    "     \n",
    "    sum_wpos_check = sum( w[i] for i in range(len(y)) if y[i] == 1.0  )\n",
    "    sum_wneg_check = sum( w[i] for i in range(len(y)) if y[i] == 0.0  )\n",
    "\n",
    "    print ('\\n======Weight Statistic========================================')\n",
    "    print ('Weights::        W(1)=%g, W(0)=%g' % (sum_wpos, sum_wneg))\n",
    "    print ('Scaled weights:: W(1)=%g, W(0)=%g' % (sum_wpos_check, sum_wneg_check))\n",
    "    print ('==============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SwFEXnfmNBw8"
   },
   "outputs": [],
   "source": [
    "def ScaleWeightsSignal(w,y):\n",
    "    sumi = sum( w[i] for i in range(len(y)) if y[i] == 1.0 )\n",
    "\n",
    "\n",
    "    for i in range(len(w)):\n",
    "      if (y[i]==1.0):\n",
    "        w[i] = sumi/len(w)\n",
    "      else: \n",
    "        w[i] = w[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZCXsLg0en3t",
    "outputId": "e659225e-afc2-4d0d-e666-c2ea90fe261d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataScaler found 10 features to train on (there were 10 total features in the input)\n",
      "Creating sample background (label = 0)\n",
      "Creating sample signal (label = 1)\n"
     ]
    }
   ],
   "source": [
    "training_samples, data_scaler = load_input_file('data/sstt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DZ3ejm3SffxD"
   },
   "outputs": [],
   "source": [
    "input_features, targets, inp_nonsc= build_combined_input(training_samples, data_scaler = data_scaler, scale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZmD_1WwHqUt_",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00140038, 0.00446875, 0.00443074, ..., 0.00461776, 0.0050069 ,\n",
       "       0.00346192])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2lSS\n",
    "weights=inp_nonsc[:,-1]\n",
    "weights[targets==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yXRVL3vggmHE"
   },
   "outputs": [],
   "source": [
    "evtnum = inp_nonsc[:,-1]\n",
    "#Drop Weight Coloumn\n",
    "inp_nonsc = inp_nonsc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hKmPR0jL9afj"
   },
   "outputs": [],
   "source": [
    "targets = targets[np.where((weights<1) &(weights>0))]\n",
    "inp_nonsc = inp_nonsc[np.where((weights<1) &(weights>0))]\n",
    "evtnum =evtnum[np.where((weights<1) &(weights>0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "40z1TOgGTmU1"
   },
   "outputs": [],
   "source": [
    "weights = weights[np.where((weights<1) &(weights>0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "X4c_YDjX6aGT",
    "outputId": "af09acdc-0359-4907-ee49-2710cca897da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f257602ba50>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot((weights[targets==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "XK3npbmj6c7L",
    "outputId": "a064935d-71c3-4829-a52f-d8b66e1c4569"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2575eca690>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7f257753def0> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     41\u001b[0m             display(\n\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/avdgraaf/.local/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2326\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 **kwargs)\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mDECORATORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \"\"\"\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    542\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    435\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2810\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 2811\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubfigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         mimage._draw_list_compositing_images(\n\u001b[0;32m-> 3083\u001b[0;31m             renderer, self, artists, self.figure.suppressComposite)\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dashes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashOffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashSeq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgbFace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOverflowError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mcant_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plt.plot(weights[targets==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlqR90IBqi19",
    "outputId": "7a97fb4b-7a3d-440c-a094-15b059d26d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Weight Statistic========================================\n",
      "Weights::        W(1)=1140.91, W(0)=471.375\n",
      "Scaled weights:: W(1)=251241, W(0)=251241\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "ScaleWeights(targets,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2COC1eAYCtEZ",
    "outputId": "34cae392-575d-4980-bf2b-fd63bb9fe0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 251241, 1: 251241})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(targets)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pQXJLfesdLZ",
    "outputId": "6651420a-d5d3-4900-9808-9ffd4b6dd2d1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00000000e+00 1.00000000e+00 5.00000000e+00 ... 3.12736250e+05\n",
      "  7.47229062e+04 2.16903047e+05]\n",
      " [6.00000000e+00 5.00000000e+00 1.00000000e+00 ... 4.32814906e+05\n",
      "  1.00001992e+05 2.22915469e+05]\n",
      " [7.00000000e+00 3.00000000e+00 2.00000000e+00 ... 5.38805375e+05\n",
      "  1.02151969e+05 9.27254219e+04]\n",
      " ...\n",
      " [3.00000000e+00 1.00000000e+00 1.00000000e+00 ... 4.50074094e+05\n",
      "  4.53176133e+04 1.78305969e+05]\n",
      " [6.00000000e+00 5.00000000e+00 5.00000000e+00 ... 7.84143625e+05\n",
      "  4.57842383e+04 9.00132969e+04]\n",
      " [3.00000000e+00 1.00000000e+00 5.00000000e+00 ... 2.91216125e+05\n",
      "  1.45114094e+05 1.12973891e+05]]\n",
      "[[ 0.01876467 -1.24122022  1.10369847 ... -0.55443049 -0.29336801\n",
      "  -0.23280678]\n",
      " [ 1.09017064  0.98226258 -1.065905   ... -0.15071604 -0.17935377\n",
      "  -0.21309283]\n",
      " [ 1.62587363 -0.12947882 -0.52350413 ...  0.20563275 -0.1696569\n",
      "  -0.63996913]\n",
      " ...\n",
      " [-0.51693832 -1.24122022 -1.065905   ... -0.09268921 -0.42599234\n",
      "  -0.3593616 ]\n",
      " [ 1.09017064  0.98226258  1.10369847 ...  1.03048039 -0.42388776\n",
      "  -0.64886184]\n",
      " [-0.51693832 -1.24122022  1.10369847 ... -0.62678294  0.02411172\n",
      "  -0.57357702]]\n"
     ]
    }
   ],
   "source": [
    "#scale the input between 0-1\n",
    "#print(inp_nonsc)\n",
    "scaler = StandardScaler().fit(inp_nonsc)\n",
    "print(inp_nonsc)\n",
    "inp_nonsc = scaler.transform(inp_nonsc)\n",
    "print(inp_nonsc)\n",
    "#inp_nonsc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "D64hk_18vSe1"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "scalerfile = path_tosave+'/scaler_standard.bin'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_bc7302zXGpX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aTZWhtxRUSVG"
   },
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch): \n",
    "  return 0.05 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UTFalfU-YlbL"
   },
   "outputs": [],
   "source": [
    "def lr_step_decay(epoch) : #initial_lr, drop, epoch_to_drop) :\n",
    "\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.9\n",
    "    epoch_to_drop = 3\n",
    "\n",
    "    if epoch >= 50 :\n",
    "        epoch == 50\n",
    "    elif epoch >= 25 :\n",
    "        epoch -= 25\n",
    "#        new_lr = initial_lr\n",
    "        print('INFO Setting learning rate back to initial LR (={})'.format(initial_lr))\n",
    "\n",
    "    new_lr = initial_lr * math.pow(drop, math.floor((1+epoch)/epoch_to_drop))\n",
    "    print('INFO LR Schedule: {}'.format(new_lr))\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nEyuBu9pz_wY"
   },
   "outputs": [],
   "source": [
    "auc_scores = []\n",
    "auc_targets = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "results = []\n",
    "model_history = []\n",
    "fitfull_history = []\n",
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OdVzc3rvvsRs"
   },
   "outputs": [],
   "source": [
    "    def fit_func2(n_classes, input_features_scale, targets, n_epochs = 400, batch_size = 2000, num_folds = 10) :\n",
    "        # Define the K-fold Cross Validator\n",
    "        #kfold = GroupKFold(n_splits=1)\n",
    "        kfold = StratifiedKFold(n_splits=2)\n",
    "        # Define per-fold score containers\n",
    "        acc_per_fold = []\n",
    "        loss_per_fold = []\n",
    "        number = int((targets.size)/2)\n",
    "        #group = [0,1]*number\n",
    "        group = evtnum % 2 ==0\n",
    "        targets_encoded=targets\n",
    "        # K-fold Cross Validation model evaluation\n",
    "        fold_no = 1\n",
    "        for train, test in kfold.split(input_features_scale, targets_encoded,group):\n",
    "            print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "            layer_opts = dict( activation = 'sigmoid', kernel_initializer = initializers.glorot_normal(seed=seed))\n",
    "            input_layer = Kl.Input(shape = (inp_nonsc.shape[1],) )\n",
    "            x = Kl.Dense( 36, **layer_opts) (input_layer)\n",
    "            x = Kl.Dropout(0.4)(x)\n",
    "            x = Kl.Dense( 48, **layer_opts) (x)\n",
    "            y_pred = Kl.Dense( 1., activation = 'sigmoid', name = \"OutputLayer\" )(x)\n",
    "            model = Km.Model(inputs= input_layer, outputs=y_pred )\n",
    "            model_optimizer = Adam(lr=0.0001)\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(),loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "            model.summary() \n",
    "            lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "            lr_schedule = tf.keras.callbacks.LearningRateScheduler(lr_step_decay)\n",
    "            # Generate a print\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} ...')\n",
    "              # Fit data to model\n",
    "            train_X, test_X = input_features_scale[train], input_features_scale[test]\n",
    "            train_y, test_y = targets_encoded[train], targets_encoded[test]\n",
    "            w_train = weights[train]\n",
    "            train_0, train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "            test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1])\n",
    "            print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))\n",
    "            fit_history = model.fit(train_X, train_y, epochs = n_epochs, shuffle = True, batch_size = batch_size ,validation_data = (test_X,test_y), sample_weight=w_train,callbacks=[tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 20, verbose = True, min_delta = 0.001),lr_schedule]) #\n",
    "            scores = model.evaluate(test_X, test_y,batch_size=batch_size, verbose=0)\n",
    "            nn_scores = model.predict(test_X,verbose = True)\n",
    "            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "            acc_per_fold.append(scores[1] * 100)\n",
    "            loss_per_fold.append(scores[0])\n",
    "            results.append(scores)\n",
    "            model_history.append(model)\n",
    "            fitfull_history.append(fit_history)\n",
    "            auc_scores.append(nn_scores)\n",
    "            auc_targets.append(targets[test])\n",
    "\n",
    "              # Increase fold number\n",
    "            fold_no = fold_no + 1\n",
    "        #fit_history = model1.fit(x_train, y_train, epochs = n_epochs, batch_size = batch_size, shuffle = True, validation_data = (x_val, y_val),callbacks=callback)\n",
    "\n",
    "        #self._fit_history = self._model.fit(x_train, y_train, epochs = n_epochs, batch_size = batch_size, shuffle = True, validation_data = (x_val, y_val), callbacks = callbacks)\n",
    "        return model_history, fitfull_history, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "sUfVYkFYfck7",
    "outputId": "72fe31b2-8daa-42f5-e7ec-8220e300f1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [125621 125622 125623 ... 502479 502480 502481] TEST: [     0      1      2 ... 376858 376859 376860]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 36)                360       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                1776      \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 2,185\n",
      "Trainable params: 2,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      ">Train: 0=125620, 1=125621, Test: 0=125621, 1=125620\n",
      "Train on 251241 samples, validate on 251241 samples\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 1/70\n",
      "251241/251241 [==============================] - 0s 2us/sample - loss: 0.3812 - accuracy: 0.8429 - val_loss: 0.2818 - val_accuracy: 0.8844\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 2/70\n",
      " 56000/251241 [=====>........................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avdgraaf/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.3146 - accuracy: 0.8799 - val_loss: 0.2756 - val_accuracy: 0.8869\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 3/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.3074 - accuracy: 0.8828 - val_loss: 0.2807 - val_accuracy: 0.8845\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 4/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.3024 - accuracy: 0.8837 - val_loss: 0.2703 - val_accuracy: 0.8883\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 5/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2999 - accuracy: 0.8843 - val_loss: 0.2715 - val_accuracy: 0.8877\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 6/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2971 - accuracy: 0.8852 - val_loss: 0.2683 - val_accuracy: 0.8888\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 7/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2955 - accuracy: 0.8857 - val_loss: 0.2664 - val_accuracy: 0.8896\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 8/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2940 - accuracy: 0.8865 - val_loss: 0.2650 - val_accuracy: 0.8898\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 9/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2926 - accuracy: 0.8869 - val_loss: 0.2645 - val_accuracy: 0.8898\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 10/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2929 - accuracy: 0.8871 - val_loss: 0.2638 - val_accuracy: 0.8902\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 11/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2907 - accuracy: 0.8876 - val_loss: 0.2628 - val_accuracy: 0.8904\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 12/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2902 - accuracy: 0.8877 - val_loss: 0.2636 - val_accuracy: 0.8906\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 13/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2895 - accuracy: 0.8879 - val_loss: 0.2628 - val_accuracy: 0.8908\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 14/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2886 - accuracy: 0.8886 - val_loss: 0.2609 - val_accuracy: 0.8914\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 15/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2891 - accuracy: 0.8885 - val_loss: 0.2618 - val_accuracy: 0.8911\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 16/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2881 - accuracy: 0.8886 - val_loss: 0.2605 - val_accuracy: 0.8916\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 17/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2877 - accuracy: 0.8887 - val_loss: 0.2613 - val_accuracy: 0.8916\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 18/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2868 - accuracy: 0.8888 - val_loss: 0.2624 - val_accuracy: 0.8914\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 19/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2869 - accuracy: 0.8892 - val_loss: 0.2615 - val_accuracy: 0.8914\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 20/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2866 - accuracy: 0.8891 - val_loss: 0.2609 - val_accuracy: 0.8921\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 21/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2866 - accuracy: 0.8890 - val_loss: 0.2597 - val_accuracy: 0.8923\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 22/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2853 - accuracy: 0.8897 - val_loss: 0.2617 - val_accuracy: 0.8914\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 23/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2860 - accuracy: 0.8891 - val_loss: 0.2603 - val_accuracy: 0.8925\n",
      "INFO LR Schedule: 0.004304672100000001\n",
      "Epoch 24/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2854 - accuracy: 0.8896 - val_loss: 0.2593 - val_accuracy: 0.8926\n",
      "INFO LR Schedule: 0.004304672100000001\n",
      "Epoch 25/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2852 - accuracy: 0.8898 - val_loss: 0.2604 - val_accuracy: 0.8924\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 26/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2849 - accuracy: 0.8898 - val_loss: 0.2593 - val_accuracy: 0.8932\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 27/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2855 - accuracy: 0.8900 - val_loss: 0.2596 - val_accuracy: 0.8929\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 28/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2842 - accuracy: 0.8897 - val_loss: 0.2593 - val_accuracy: 0.8934\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 29/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2844 - accuracy: 0.8906 - val_loss: 0.2578 - val_accuracy: 0.8933\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 30/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2835 - accuracy: 0.8908 - val_loss: 0.2581 - val_accuracy: 0.8933\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 31/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2830 - accuracy: 0.8905 - val_loss: 0.2600 - val_accuracy: 0.8924\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 32/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2837 - accuracy: 0.8905 - val_loss: 0.2577 - val_accuracy: 0.8940\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 33/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2829 - accuracy: 0.8908 - val_loss: 0.2582 - val_accuracy: 0.8936\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 34/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2823 - accuracy: 0.8911 - val_loss: 0.2590 - val_accuracy: 0.8935\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 35/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2819 - accuracy: 0.8909 - val_loss: 0.2577 - val_accuracy: 0.8939\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 36/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2818 - accuracy: 0.8912 - val_loss: 0.2569 - val_accuracy: 0.8941\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 37/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2821 - accuracy: 0.8914 - val_loss: 0.2570 - val_accuracy: 0.8940\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 38/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2821 - accuracy: 0.8916 - val_loss: 0.2577 - val_accuracy: 0.8940\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 39/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2819 - accuracy: 0.8914 - val_loss: 0.2578 - val_accuracy: 0.8943\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 40/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2808 - accuracy: 0.8914 - val_loss: 0.2579 - val_accuracy: 0.8941\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 41/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2809 - accuracy: 0.8917 - val_loss: 0.2594 - val_accuracy: 0.8942\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 42/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2810 - accuracy: 0.8913 - val_loss: 0.2588 - val_accuracy: 0.8942\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 43/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2809 - accuracy: 0.8916 - val_loss: 0.2582 - val_accuracy: 0.8942\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 44/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2806 - accuracy: 0.8922 - val_loss: 0.2586 - val_accuracy: 0.8942\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 45/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2807 - accuracy: 0.8917 - val_loss: 0.2586 - val_accuracy: 0.8939\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 46/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2802 - accuracy: 0.8917 - val_loss: 0.2589 - val_accuracy: 0.8941\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 47/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2802 - accuracy: 0.8921 - val_loss: 0.2585 - val_accuracy: 0.8944\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 48/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2799 - accuracy: 0.8911 - val_loss: 0.2587 - val_accuracy: 0.8941\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004304672100000001\n",
      "Epoch 49/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2793 - accuracy: 0.8920 - val_loss: 0.2610 - val_accuracy: 0.8943\n",
      "Epoch 00049: early stopping\n",
      "Score for fold 1: loss of 0.26096926214905497; accuracy of 89.43365216255188%\n",
      "TRAIN: [     0      1      2 ... 376858 376859 376860] TEST: [125621 125622 125623 ... 502479 502480 502481]\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                360       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                1776      \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 2,185\n",
      "Trainable params: 2,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      ">Train: 0=125621, 1=125620, Test: 0=125620, 1=125621\n",
      "Train on 251241 samples, validate on 251241 samples\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 1/70\n",
      "251241/251241 [==============================] - 0s 2us/sample - loss: 0.3873 - accuracy: 0.8341 - val_loss: 0.2833 - val_accuracy: 0.8838\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 2/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.3161 - accuracy: 0.8792 - val_loss: 0.2768 - val_accuracy: 0.8865\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 3/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.3089 - accuracy: 0.8818 - val_loss: 0.2744 - val_accuracy: 0.8870\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 4/70\n",
      "251241/251241 [==============================] - 0s 2us/sample - loss: 0.3036 - accuracy: 0.8832 - val_loss: 0.2696 - val_accuracy: 0.8887\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 5/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.3006 - accuracy: 0.8845 - val_loss: 0.2699 - val_accuracy: 0.8880\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 6/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2985 - accuracy: 0.8850 - val_loss: 0.2657 - val_accuracy: 0.8896\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 7/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2960 - accuracy: 0.8853 - val_loss: 0.2646 - val_accuracy: 0.8903\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 8/70\n",
      "251241/251241 [==============================] - 0s 2us/sample - loss: 0.2939 - accuracy: 0.8863 - val_loss: 0.2654 - val_accuracy: 0.8902\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 9/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2933 - accuracy: 0.8867 - val_loss: 0.2634 - val_accuracy: 0.8905\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 10/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2923 - accuracy: 0.8871 - val_loss: 0.2613 - val_accuracy: 0.8915\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 11/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2915 - accuracy: 0.8876 - val_loss: 0.2626 - val_accuracy: 0.8909\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 12/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2909 - accuracy: 0.8874 - val_loss: 0.2624 - val_accuracy: 0.8907\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 13/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2904 - accuracy: 0.8877 - val_loss: 0.2615 - val_accuracy: 0.8912\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 14/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2889 - accuracy: 0.8884 - val_loss: 0.2603 - val_accuracy: 0.8920\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 15/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2886 - accuracy: 0.8882 - val_loss: 0.2620 - val_accuracy: 0.8915\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 16/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2883 - accuracy: 0.8887 - val_loss: 0.2631 - val_accuracy: 0.8901\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 17/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2884 - accuracy: 0.8884 - val_loss: 0.2602 - val_accuracy: 0.8922\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 18/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2870 - accuracy: 0.8887 - val_loss: 0.2597 - val_accuracy: 0.8922\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 19/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2875 - accuracy: 0.8894 - val_loss: 0.2602 - val_accuracy: 0.8920\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 20/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2869 - accuracy: 0.8890 - val_loss: 0.2607 - val_accuracy: 0.8917\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 21/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2864 - accuracy: 0.8900 - val_loss: 0.2600 - val_accuracy: 0.8925\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 22/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2862 - accuracy: 0.8895 - val_loss: 0.2596 - val_accuracy: 0.8923\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 23/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2862 - accuracy: 0.8892 - val_loss: 0.2594 - val_accuracy: 0.8925\n",
      "INFO LR Schedule: 0.004304672100000001\n",
      "Epoch 24/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2863 - accuracy: 0.8892 - val_loss: 0.2595 - val_accuracy: 0.8916\n",
      "INFO LR Schedule: 0.004304672100000001\n",
      "Epoch 25/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2855 - accuracy: 0.8896 - val_loss: 0.2579 - val_accuracy: 0.8928\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 26/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2858 - accuracy: 0.8897 - val_loss: 0.2594 - val_accuracy: 0.8921\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.01\n",
      "Epoch 27/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2856 - accuracy: 0.8897 - val_loss: 0.2596 - val_accuracy: 0.8925\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 28/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2848 - accuracy: 0.8900 - val_loss: 0.2587 - val_accuracy: 0.8923\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 29/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2846 - accuracy: 0.8901 - val_loss: 0.2605 - val_accuracy: 0.8912\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.009000000000000001\n",
      "Epoch 30/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2842 - accuracy: 0.8901 - val_loss: 0.2581 - val_accuracy: 0.8922\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 31/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2842 - accuracy: 0.8903 - val_loss: 0.2587 - val_accuracy: 0.8921\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 32/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2843 - accuracy: 0.8900 - val_loss: 0.2584 - val_accuracy: 0.8929\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.008100000000000001\n",
      "Epoch 33/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2834 - accuracy: 0.8902 - val_loss: 0.2566 - val_accuracy: 0.8940\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 34/70\n",
      "251241/251241 [==============================] - 0s 2us/sample - loss: 0.2834 - accuracy: 0.8903 - val_loss: 0.2568 - val_accuracy: 0.8933\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 35/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2829 - accuracy: 0.8908 - val_loss: 0.2591 - val_accuracy: 0.8925\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.007290000000000001\n",
      "Epoch 36/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2824 - accuracy: 0.8908 - val_loss: 0.2580 - val_accuracy: 0.8931\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 37/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2827 - accuracy: 0.8906 - val_loss: 0.2613 - val_accuracy: 0.8914\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 38/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2832 - accuracy: 0.8905 - val_loss: 0.2555 - val_accuracy: 0.8940\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.006561\n",
      "Epoch 39/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2829 - accuracy: 0.8906 - val_loss: 0.2563 - val_accuracy: 0.8942\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 40/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2821 - accuracy: 0.8907 - val_loss: 0.2562 - val_accuracy: 0.8940\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 41/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2822 - accuracy: 0.8913 - val_loss: 0.2567 - val_accuracy: 0.8938\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.005904900000000001\n",
      "Epoch 42/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2819 - accuracy: 0.8914 - val_loss: 0.2568 - val_accuracy: 0.8936\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 43/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2818 - accuracy: 0.8914 - val_loss: 0.2592 - val_accuracy: 0.8917\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 44/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2816 - accuracy: 0.8913 - val_loss: 0.2574 - val_accuracy: 0.8932\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.00531441\n",
      "Epoch 45/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2816 - accuracy: 0.8911 - val_loss: 0.2568 - val_accuracy: 0.8941\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 46/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2817 - accuracy: 0.8911 - val_loss: 0.2572 - val_accuracy: 0.8945\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 47/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2821 - accuracy: 0.8914 - val_loss: 0.2589 - val_accuracy: 0.8930\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004782969000000001\n",
      "Epoch 48/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2812 - accuracy: 0.8916 - val_loss: 0.2567 - val_accuracy: 0.8941\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004304672100000001\n",
      "Epoch 49/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2815 - accuracy: 0.8914 - val_loss: 0.2569 - val_accuracy: 0.8943\n",
      "INFO Setting learning rate back to initial LR (=0.01)\n",
      "INFO LR Schedule: 0.004304672100000001\n",
      "Epoch 50/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2807 - accuracy: 0.8916 - val_loss: 0.2570 - val_accuracy: 0.8933\n",
      "INFO LR Schedule: 0.0016677181699666576\n",
      "Epoch 51/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2804 - accuracy: 0.8913 - val_loss: 0.2561 - val_accuracy: 0.8944\n",
      "INFO LR Schedule: 0.0016677181699666576\n",
      "Epoch 52/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2813 - accuracy: 0.8913 - val_loss: 0.2567 - val_accuracy: 0.8941\n",
      "INFO LR Schedule: 0.0016677181699666576\n",
      "Epoch 53/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2801 - accuracy: 0.8915 - val_loss: 0.2559 - val_accuracy: 0.8941\n",
      "INFO LR Schedule: 0.0015009463529699917\n",
      "Epoch 54/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2805 - accuracy: 0.8913 - val_loss: 0.2564 - val_accuracy: 0.8939\n",
      "INFO LR Schedule: 0.0015009463529699917\n",
      "Epoch 55/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2803 - accuracy: 0.8917 - val_loss: 0.2562 - val_accuracy: 0.8941\n",
      "INFO LR Schedule: 0.0015009463529699917\n",
      "Epoch 56/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2804 - accuracy: 0.8917 - val_loss: 0.2566 - val_accuracy: 0.8936\n",
      "INFO LR Schedule: 0.0013508517176729928\n",
      "Epoch 57/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2809 - accuracy: 0.8914 - val_loss: 0.2566 - val_accuracy: 0.8940\n",
      "INFO LR Schedule: 0.0013508517176729928\n",
      "Epoch 58/70\n",
      "251241/251241 [==============================] - 0s 1us/sample - loss: 0.2805 - accuracy: 0.8913 - val_loss: 0.2565 - val_accuracy: 0.8942\n",
      "Epoch 00058: early stopping\n",
      "Score for fold 2: loss of 0.2564664055111487; accuracy of 89.41614031791687%\n"
     ]
    }
   ],
   "source": [
    "my_model_fin_func, fit_history_func,results = fit_func2( len(training_samples)-1, inp_nonsc, targets, n_epochs = 70, batch_size = 2000, num_folds = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "T-20FxuymeZj",
    "outputId": "35ee3260-a5b0-4eaa-b78c-0003244332d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in range(0,2):\n",
    "    plt.plot(fit_history_func[x].history['loss'], label='Train. fold-'+str(x))\n",
    "    plt.plot(fit_history_func[x].history['val_loss'], label='Val. fold-'+str(x))\n",
    "    plt.title('DNN ($D_{in}$=7, $D_{hidden}$=2, 0.2Drop)')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "saveit = \"{}/{}\".format(path_tosave, \"dnn_lossepo.png\") \n",
    "plt.savefig(saveit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "nrUmodWPsH_J",
    "outputId": "9f622150-77db-47d5-a6d5-58ab567fbbf3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in range(0,2):\n",
    "    plt.plot(fit_history_func[x].history['accuracy'], label='Train. fold-'+str(x))\n",
    "    plt.plot(fit_history_func[x].history['val_accuracy'], label='Val. fold-'+str(x))\n",
    "    plt.title('DNN ($D_{in}$=7, $D_{hidden}$=2, 0.2Drop)')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "saveit = \"{}/{}\".format(path_tosave, \"dnn_accepo.png\") \n",
    "plt.savefig(saveit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZoElcyiKvl3",
    "outputId": "e7032ad5-b209-46ca-dfea-51e266bee5d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving architecture to: /mnt/c/Users/aaron/Desktop/sstt/architecture_cift_2hdm.json\n",
      "Saving weights to     : /mnt/c/Users/aaron/Desktop/sstt/weights_cift_2hdm.h5\n"
     ]
    }
   ],
   "source": [
    "output_dir = path_tosave\n",
    "file_name = \"2hdm\"\n",
    "job_suff = \"_{}\".format(file_name)\n",
    "arch_name = \"architecture_cift{}.json\".format(job_suff)\n",
    "weights_name = \"weights_cift{}.h5\".format(job_suff)\n",
    "\n",
    "mkdir_p(output_dir)\n",
    "arch_name = \"{}/{}\".format(output_dir, arch_name)\n",
    "weights_name = \"{}/{}\".format(output_dir, weights_name)\n",
    "\n",
    "print(\"Saving architecture to: {}\".format(os.path.abspath(arch_name)))\n",
    "print(\"Saving weights to     : {}\".format(os.path.abspath(weights_name)))\n",
    "with open(arch_name, 'w') as arch_file :\n",
    "    arch_file.write(my_model_fin_func[0].to_json())\n",
    "my_model_fin_func[0].save_weights(weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pHSmDQU3kfe",
    "outputId": "494f2ab7-b35d-48bd-e3d1-50bbcdc86c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving architecture to: /mnt/c/Users/aaron/Desktop/sstt/architecture_tek_2hdm.json\n",
      "Saving weights to     : /mnt/c/Users/aaron/Desktop/sstt/weights_tek_2hdm.h5\n"
     ]
    }
   ],
   "source": [
    "output_dir = path_tosave\n",
    "file_name = \"2hdm\"\n",
    "job_suff = \"_{}\".format(file_name)\n",
    "arch_name = \"architecture_tek{}.json\".format(job_suff)\n",
    "weights_name = \"weights_tek{}.h5\".format(job_suff)\n",
    "\n",
    "mkdir_p(output_dir)\n",
    "arch_name = \"{}/{}\".format(output_dir, arch_name)\n",
    "weights_name = \"{}/{}\".format(output_dir, weights_name)\n",
    "\n",
    "print(\"Saving architecture to: {}\".format(os.path.abspath(arch_name)))\n",
    "print(\"Saving weights to     : {}\".format(os.path.abspath(weights_name)))\n",
    "with open(arch_name, 'w') as arch_file :\n",
    "    arch_file.write(my_model_fin_func[1].to_json())\n",
    "my_model_fin_func[1].save_weights(weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oxNjLvpNL8Ey"
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "def load_model(arch_path, weights_path) :\n",
    "    #arch_name = \"/home/jovyan/test2/architecture_test2.json\"\n",
    "    #weights_name = \"/home/jovyan/test2/weights_test2.h5\"\n",
    "    print(os.path.abspath(arch_path))\n",
    "    print(\"Loading model architecture and weights (%, %)\".format(os.path.abspath(arch_path), os.path.abspath(weights_path)))\n",
    "    from tensorflow.keras.models import model_from_json\n",
    "    json_file = open(os.path.abspath(arch_path), 'r')\n",
    "    loaded_model = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model)\n",
    "    loaded_model.load_weights(os.path.abspath(weights_path))\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DM1fYymh4Cap",
    "outputId": "95dd63dc-b15f-4a99-e8f6-5d6838b6e28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/aaron/Desktop/sstt/architecture_cift_2hdm.json\n",
      "Loading model architecture and weights (%, %)\n"
     ]
    }
   ],
   "source": [
    "arch_path = \"{}/architecture_cift_2hdm.json\".format(path_tosave)\n",
    "weights_path = \"{}/weights_cift_2hdm.h5\".format(path_tosave)\n",
    "my_model_loaded_cift = load_model(arch_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlDtNWcw4JHD",
    "outputId": "af56f23c-c0a7-486f-d3ac-dde419fdcdc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/aaron/Desktop/sstt/architecture_tek_2hdm.json\n",
      "Loading model architecture and weights (%, %)\n"
     ]
    }
   ],
   "source": [
    "arch_path = \"{}/architecture_tek_2hdm.json\".format(path_tosave)\n",
    "weights_path = \"{}/weights_tek_2hdm.h5\".format(path_tosave)\n",
    "my_model_loaded_tek = load_model(arch_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_mDE9lkY5jAU",
    "outputId": "ef92fdff-3b0a-4e23-9fd0-b66e02d1b93c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5e6172f0e4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn_scores_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_nn_output_plots_oddeven\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpath_tosave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmy_model_loaded_cift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_model_loaded_tek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp_nonsc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_samples\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevtnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-fa05ba86338b>\u001b[0m in \u001b[0;36mmake_nn_output_plots_oddeven\u001b[0;34m(path_tosave, model, inputs, samples, targets, events)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Shuffle + split into two equal size arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0minputs_tek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0minputs_cift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs_test' is not defined"
     ]
    }
   ],
   "source": [
    "nn_scores_2 = make_nn_output_plots_oddeven( path_tosave, [my_model_loaded_cift,my_model_loaded_tek], inputs = inp_nonsc, samples = training_samples,  targets = targets, events=evtnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jkN0DGfUxVR"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(pred,truth,label):\n",
    "    fpr, tpr, thr = roc_curve(truth, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(path_tosave+\"/roc{}.png\".format(label))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xH9j7ftKb9E"
   },
   "outputs": [],
   "source": [
    "nn_scores = nn_scores_2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "43TF9vxAUyRV",
    "outputId": "0629d30b-10b8-46b3-da73-45cbcadf2086"
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(nn_scores,targets,\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6cH3oqn9hLW",
    "outputId": "9fb4a4f8-8303-459e-9047-84b7daad1343"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "area = trapz(targets, dx=5)\n",
    "print(\"area =\", area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "Hv3Onfauzg6y",
    "outputId": "18e81ef8-38d1-489f-caea-e492bfd2d823"
   },
   "outputs": [],
   "source": [
    "plt.figure(0).clf()\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=[8,6])\n",
    "color = ['blue', 'orange', 'red', 'green', 'coral',\n",
    "             'grey', 'indigo', 'gold', 'lime', 'olive',\n",
    "             'pink', 'navy', 'magenta', 'yellow', 'tomato',\n",
    "             'turquoise', 'yellowgreen', 'maroon', 'lightblue']\n",
    "\n",
    "\n",
    "fpr, tpr, thr = roc_curve(targets,nn_scores_2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color=color[0], lw=1,\n",
    "             label='ROC curve w/ dCorr train (area = {:.2f})'.format(roc_auc),linestyle='dashed')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "fpr, tpr, thr = roc_curve(targets_val,nn_scores_val)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color=color[1], lw=1,\n",
    "             label='ROC curve w/ dCorr val (area = {:.2f})'.format(roc_auc),linestyle='solid')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_1MQw0JUTJL"
   },
   "outputs": [],
   "source": [
    "import mplhep as hep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBVZH0xJUWat"
   },
   "outputs": [],
   "source": [
    "input_features2, targets2, inp_nonsc2= build_combined_input(training_samples, data_scaler = data_scaler, scale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "a5kDaNGgUbS0",
    "outputId": "e28eaa18-86cd-44c6-e3a8-f939e463726f"
   },
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "\n",
    "bins = np.arange(0,800,10)\n",
    "bins2 = np.arange(0.0,1.0,0.1)\n",
    "f, ax = plt.subplots()\n",
    "h4 = np.array([])\n",
    "h5 = np.array([])\n",
    "h6 = np.array([])\n",
    "#for i, j in df44.iterrows(): \n",
    "#    h4 = np.append(h4, j[df4['ptnames2'][i]]/1000)\n",
    "\n",
    "#for i, j in df55.iterrows(): \n",
    "#    h5 = np.append(h5, j[df5['ptnames2'][i]]/1000)\n",
    "#print(h)\n",
    "#for i, j in df66.iterrows(): \n",
    "#    h6 = np.append(h6, j[df6['ptnames2'][i]]/1000)\n",
    "pt = inp_nonsc2[:,6]/1000\n",
    "signalpt = pt[targets==1]\n",
    "backpt = pt[targets==0]\n",
    "signal_sc = nn_scores_2[targets==1]\n",
    "back_sc = nn_scores_2[targets==0]\n",
    "h44, bins = np.histogram(signalpt, bins)\n",
    "h55, bins = np.histogram(backpt, bins)\n",
    "#h66, bins = np.histogram(h6, bins)\n",
    "h1,bins2 = np.histogram(signal_sc, bins2)\n",
    "h2,bins2 = np.histogram(back_sc, bins2)\n",
    "\n",
    "hep.histplot([h44 ,h55], bins ,label=['signal','back'], linewidth=2.0, density=True)\n",
    "\n",
    "#    print() \n",
    "#row = next(df2.iterrows())[1]\n",
    "#print(row)\n",
    "ax.legend()\n",
    "#ax.set_xlabel(\"$p_T$ of the c-jet\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "LJkMtXj0Ut_D",
    "outputId": "a4ad2a06-6fa0-4616-a3e3-8732d18999c1"
   },
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "f1, ax1 = plt.subplots()\n",
    "h1,bins2 = np.histogram(signal_sc, bins2)\n",
    "h2,bins2 = np.histogram(back_sc, bins2)\n",
    "hep.histplot([h1 ,h2], bins2 ,label=['signal','back'], linewidth=2.0, density=True)\n",
    "ax1.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SvsBsstt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
